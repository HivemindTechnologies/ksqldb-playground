SET 'auto.offset.reset' = 'earliest';

CREATE STREAM `sensor-data-s3` WITH (
  kafka_topic = 'sensor-data-s3',
  value_format = 'JSON_SR'
) AS
SELECT
  s.`sensor`,
  s.`temperature` AS `temperature`,
  s.`humidity` AS `humidity`,
  s.`pressure` AS `pressure`,
  l.`location` AS `location`,
  AS_VALUE(s.`sensor`) AS `sensor`
FROM
  `sensor-data` s
  JOIN `sensor-location-table` l ON s.`sensor` = l.`sensor`
EMIT CHANGES;

CREATE SINK CONNECTOR `s3_sink` WITH (
  'connector.class'                     = 'io.confluent.connect.s3.S3SinkConnector',
  'tasks.max'                           = '1',
  'topics'                              = 'sensor-data-s3',
  's3.region'                           = 'us-east-1',
  's3.bucket.name'                      = 'sink-bucket',
  's3.part.size'                        = '5242880',
  'store.url'                           = 'http://minio:9000',
  'flush.size'                          = '100',
  'storage.class'                       = 'io.confluent.connect.s3.storage.S3Storage',
  'format.class'                        = 'io.confluent.connect.s3.format.parquet.ParquetFormat',
  'partitioner.class'                   = 'io.confluent.connect.storage.partitioner.TimeBasedPartitioner',
  'timestamp.extractor'                 = 'Record',
  'path.format'                         = '''year''=YYYY/''month''=MM/''day''=dd/''hour''=HH',
  'locale'                              = 'en-US',
  'timezone'                            = 'UTC',
  'partition.duration.ms'               = '600000',
  'value.converter'                     = 'io.confluent.connect.json.JsonSchemaConverter',
  'value.converter.schema.registry.url' = 'http://schema-registry:8081'
);
